# Copyright 2025 Fraunhofer AISEC
# Fraunhofer-Gesellschaft zur FÃ¶rderung der angewandten Forschung e.V.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Perform ground-truth analysis of deduplication results."""

import argparse
import logging
from collections import defaultdict
from json import dumps as json_dumps
from pathlib import Path


def get_undercounting(
    bug_cluster_dict: defaultdict[str, defaultdict[int, int]], summary_path: Path
) -> int:
    """Check for clusters that contain traces associated to different bugs."""
    unique_cluster_labels = {
        cluster_label
        for cluster_dict in bug_cluster_dict.values()
        for cluster_label in cluster_dict.keys()
    }

    num_undercounting = 0
    for cluster_label in unique_cluster_labels:
        bugs_assigned_to_cluster_label = [
            bug_label
            for bug_label, cluster_dict in bug_cluster_dict.items()
            if cluster_label in cluster_dict
        ]
        if len(bugs_assigned_to_cluster_label) > 1:
            num_undercounting += 1
            logging.info(
                f"Undercounting present at cluster {cluster_label}: "
                f"{bugs_assigned_to_cluster_label}"
            )
            with open(summary_path, "a") as summary:
                summary.write(
                    f"Undercounting present at cluster {cluster_label}: "
                    f"{bugs_assigned_to_cluster_label}\n"
                )
    return num_undercounting


def get_overcounting(
    bug_cluster_dict: defaultdict[str, defaultdict[int, int]], summary_path: Path
) -> int:
    """Check for bugs that have traces in multiple clusters."""
    overcounting_list = [
        (bug_label, len(cluster_dict))
        for bug_label, cluster_dict in bug_cluster_dict.items()
        if len(cluster_dict) > 1
    ]
    with open(summary_path, "w") as summary:
        for oc in overcounting_list:
            logging.info(f"Overcounting bug_type {oc[0]}: present in {oc[1]} clusters.")
            summary.write(
                f"Overcounting bug_type {oc[0]}: present in {oc[1]} clusters.\n"
            )

    return len(overcounting_list)


def get_lost(
    bug_cluster_dict: defaultdict[str, defaultdict[int, int]],
) -> tuple[int, set[str]]:
    """Check for bugs that do not have at least one pure cluster."""
    num_lost = 0
    lost_list: set[str] = set()
    for bug_label in bug_cluster_dict.keys():
        cluster_dict = bug_cluster_dict[bug_label]
        other_bug_cluster_dict = {
            other_bug_label: bug_cluster_dict[other_bug_label]
            for other_bug_label in bug_cluster_dict
            if other_bug_label != bug_label
        }
        if all(
            [
                any(
                    [
                        cluster_label in other_cluster_dict
                        for other_cluster_dict in other_bug_cluster_dict.values()
                    ]
                )
                for cluster_label in cluster_dict
            ]
        ):
            num_lost += 1
            lost_list.add(bug_label)

    return num_lost, lost_list


def index_sets(
    cluster_list: list[int], bug_list: list[str]
) -> tuple[dict[int, set[int]], dict[str, set[int]]]:
    """Compute index lists that are needed for statistical computations."""
    index_cluster: dict[int, set[int]] = {}
    for cluster in set(cluster_list):
        index_cluster[cluster] = {
            n
            for n, other_cluster in enumerate(cluster_list)
            if other_cluster == cluster
        }

    index_bug: dict[str, set[int]] = {}
    for bug in set(bug_list):
        index_bug[bug] = {n for n, other_bug in enumerate(bug_list) if other_bug == bug}

    return index_cluster, index_bug


def purity(
    cluster_list: list[int],
    bug_list: list[str],
    index_cluster: dict[int, set[int]],
    index_bug: dict[str, set[int]],
    num_decimal_places: int = 5,
) -> float:
    """Compute purity."""
    purity: float = 0
    N = len(cluster_list)

    for i in set(cluster_list):
        C_i = cluster_list.count(i)
        index_cluster_i = index_cluster[i]

        maxP: float = 0
        for j in set(bug_list):
            index_bug_j = index_bug[j]

            intersection = len(index_cluster_i & index_bug_j)

            P = intersection / C_i
            if P > maxP:
                maxP = P

        purity += maxP * C_i / N

    return round(purity, num_decimal_places)


def inverse_purity(
    cluster_list: list[int],
    bug_list: list[str],
    index_cluster: dict[int, set[int]],
    index_bug: dict[str, set[int]],
    num_decimal_places: int = 5,
) -> float:
    """Compute inverse purity."""
    inverse_purity: float = 0
    N = len(cluster_list)

    for i in set(bug_list):
        L_i = bug_list.count(i)
        index_bug_i = index_bug[i]

        maxP: float = 0
        for j in set(cluster_list):
            index_cluster_j = index_cluster[j]

            intersection = len(index_bug_i & index_cluster_j)

            P = intersection / L_i
            if P > maxP:
                maxP = P

        inverse_purity += maxP * L_i / N

    return round(inverse_purity, num_decimal_places)


def f_measure(
    cluster_list: list[int],
    bug_list: list[str],
    index_cluster: dict[int, set[int]],
    index_bug: dict[str, set[int]],
    num_decimal_places: int = 5,
) -> float:
    """Compute F-measure."""
    f_measure: float = 0
    N = len(cluster_list)

    C_counts: dict[int, int] = {}
    for j in set(cluster_list):
        C_counts[j] = cluster_list.count(j)

    for i in set(bug_list):
        L_i = bug_list.count(i)
        index_bug_i = index_bug[i]

        maxF: float = 0
        for j in set(cluster_list):
            C_j = C_counts[j]
            index_cluster_j = index_cluster[j]

            intersection = len(index_bug_i & index_cluster_j)

            R = intersection / C_j
            P = intersection / L_i

            if R == 0 and P == 0:
                F: float = 0
            else:
                F = 2 * R * P / (R + P)

            if F > maxF:
                maxF = F

        f_measure += maxF * L_i / N

    return round(f_measure, num_decimal_places)


def statistical_scores(
    cluster_list: list[int], bug_list: list[str]
) -> tuple[float, float, float]:
    """Compute purity, inverse purity and F-measure."""
    index_cluster, index_bug = index_sets(cluster_list, bug_list)

    p = purity(cluster_list, bug_list, index_cluster, index_bug)
    ip = inverse_purity(cluster_list, bug_list, index_cluster, index_bug)
    f = f_measure(cluster_list, bug_list, index_cluster, index_bug)

    return (p, ip, f)


def get_dist_data(
    groups: list[list[Path]],
) -> tuple[defaultdict[str, defaultdict[int, int]], list[int], list[str]]:
    """Produce various structures that contain distribution information."""
    # Dictionary that, for each bug type, stores how many associated traces have been
    # assigned to each individual cluster.
    bug_cluster_dict: defaultdict[str, defaultdict[int, int]] = defaultdict(
        lambda: defaultdict(int)
    )

    # List that contain for all (also duplicate) traces the clustering label and the
    # ground-truth label, in the same order
    cluster_list: list[int] = []
    bug_list: list[str] = []

    for i, cluster in enumerate(groups):
        for trace_path in cluster:
            bug_label = trace_path.parent.name
            bug_cluster_dict[bug_label][i] += 1
            cluster_list.append(i)
            bug_list.append(bug_label)

    return bug_cluster_dict, cluster_list, bug_list


def decimal_to_int_percentage(x: float) -> int:
    """Convert decimal value to integer percentage."""
    return int(100 * x + 0.5)


def analyze_clustering_performance(
    groups: list[list[Path]],
    summary_path: Path,
    round: bool = True,
):
    """Do ground-truth analysis."""
    num_clusters = len(groups)
    bug_cluster_dict, cluster_list, bug_list = get_dist_data(groups)

    num_overcounting = get_overcounting(bug_cluster_dict, summary_path)
    num_undercounting = get_undercounting(bug_cluster_dict, summary_path)
    num_lost, lost_list = get_lost(bug_cluster_dict)
    p, ip, f = statistical_scores(cluster_list, bug_list)

    if round:
        p = decimal_to_int_percentage(p)
        ip = decimal_to_int_percentage(ip)
        f = decimal_to_int_percentage(f)

    ground_truth_results = {
        "num_clusters": num_clusters,
        "num_overcount": num_overcounting,
        "num_undercount": num_undercounting,
        "num_completely_lost": num_lost,
        "purity": p,
        "inverse_purity": ip,
        "f_measure": f,
    }

    with open(summary_path, "a") as summary:
        logging.info(f"Ground truth analysis:\n{json_dumps(ground_truth_results)}")
        summary.write(json_dumps(ground_truth_results) + "\n")
        for b in lost_list:
            logging.info(f"Bug {b} has no distinct cluster and will be lost")
            summary.write(f"Bug {b} has no distinct cluster and will be lost\n")


def parse_groups(group_path: Path) -> list[list[Path]]:
    """Get path lists from group file tree."""
    group_files = group_path.glob("**/*")
    result = []
    for group in group_files:
        if group.name == "summary":
            continue

        with group.open(encoding="utf-8") as g:
            trace_paths = [Path(line.strip()) for line in g if line.strip()]
        if len(trace_paths) > 0:
            result.append(trace_paths)
    return result


def main():
    """Execute ground-truth analysis as standalone script."""
    parser = argparse.ArgumentParser(description="Ground-truth analysis script")
    parser.add_argument("group_path", help="path to groups", type=Path)
    parser.add_argument(
        "-o",
        "--output_path",
        help="path to output file which stores the results",
        type=Path,
    )
    args = parser.parse_args()
    logging.basicConfig(level=logging.INFO)

    groups = parse_groups(args.group_path)
    analyze_clustering_performance(groups, args.output_path)


if __name__ == "__main__":
    main()
